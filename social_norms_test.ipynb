{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"metaeval/social-chemestry-101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['area', 'm', 'split', 'rot-agree', 'rot-categorization', 'rot-moral-foundations', 'rot-char-targeting', 'rot-bad', 'rot-judgment', 'action', 'action-agency', 'action-moral-judgment', 'action-agree', 'action-legal', 'action-pressure', 'action-char-involved', 'action-hypothetical', 'situation', 'situation-short-id', 'rot', 'rot-id', 'rot-worker-id', 'breakdown-worker-id', 'n-characters', 'characters'],\n",
       "        num_rows: 355922\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'area': 'amitheasshole',\n",
       " 'm': 1,\n",
       " 'split': 'train',\n",
       " 'rot-agree': 3.0,\n",
       " 'rot-categorization': 'morality-ethics',\n",
       " 'rot-moral-foundations': 'care-harm|loyalty-betrayal',\n",
       " 'rot-char-targeting': 'char-1',\n",
       " 'rot-bad': 0,\n",
       " 'rot-judgment': \"it's okay\",\n",
       " 'action': 'feeling angry when you find out your roommate lied to you',\n",
       " 'action-agency': 'experience',\n",
       " 'action-moral-judgment': None,\n",
       " 'action-agree': 3.0,\n",
       " 'action-legal': None,\n",
       " 'action-pressure': None,\n",
       " 'action-char-involved': None,\n",
       " 'action-hypothetical': None,\n",
       " 'situation': \"telling my roommate with 2 months notice that I'm going to move out, then after he bought a house to live in, change my mind and getting a new roommate\",\n",
       " 'situation-short-id': 'reddit/amitheasshole/adwxny',\n",
       " 'rot': \"If you find out that your roommate lied to you, it's okay to feel angry.\",\n",
       " 'rot-id': 'rot/reddit/amitheasshole/adwxny/3DH6GAKTY14IXU2D5WHPXGPIFGTZYG/129/4',\n",
       " 'rot-worker-id': 129,\n",
       " 'breakdown-worker-id': 17,\n",
       " 'n-characters': 3,\n",
       " 'characters': 'narrator|my roommate|a new roommate'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'rot' = 'rot-judgement' + 'action'.  1–5 RoTs for each 'situation'    (see https://github.com/mbforbes/social-chemistry-101)\n",
    "\n",
    "##### RoT attributes:\n",
    "- rot\n",
    "- rot-agree: asks how many people probably agree with the RoT as stated. How universally held is the rule-of-thumb as a belief?\n",
    "    - 0: almost no one\n",
    "    - 1: uncommon\n",
    "    - 2: contreversial\n",
    "    - 3: common\n",
    "    - 4: universal\n",
    "- rot-categorization: the category of the rule of thumb. (15 in total)\n",
    "- rot-moral-foundations: define fundamental axes of morality. (5 in total)\n",
    "- rot-char-targeting: The relevant character who in the situation is the person to who you would tell this rule-of-thumb. e.g. char-1 = my roommate (characters[1])\n",
    "- rot-bad: 0 or 1, 98% of elements have the value 0\n",
    "- rot-judgement: the judgement of the action\n",
    "\n",
    "##### Action attributes:\n",
    "- action\n",
    "- action-agency: agency or experience (is designed to let workers distinguish RoTs that involve agentive action from those that indicate an an experience)\n",
    "- action-moral-judgment: This is an intuitive reaction of whether something is good or bad.\n",
    "    - -2: very bad\n",
    "    - -1: bad\n",
    "    - 0: expected/OK\n",
    "    - 1: good\n",
    "    - 2: very good\n",
    "- action-agree: what portion of people probably agree with the judgment given the action\n",
    "    - 0: rare (< 1%)\n",
    "    - 1: few (5-25%)\n",
    "    - 2: controversial (~50%)\n",
    "    - 3: most (75-90%)\n",
    "    - 4: all (> 99%)\n",
    "- action-legal: corresponds to prescriptive norms: what one ought to do (legal, tolerated, illegal, null)\n",
    "- action-pressure: cultural pressure, measures to what degree someone feels socially influenced to do (or avoid) an action.\n",
    "    - -2: strongly-against\n",
    "    - -1: against\n",
    "    - 0: discretionary\n",
    "    - 1: for\n",
    "    - 2: strongly for\n",
    "- action-char-involved: \n",
    "- action-hypothetical: indicates whether the candidate character is explicitly taking the action in the situation: explicit-no, probable-no, hypothetical, probable, explicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['area', 'm', 'split', 'rot-agree', 'rot-categorization', 'rot-moral-foundations', 'rot-char-targeting', 'rot-bad', 'rot-judgment', 'action', 'action-agency', 'action-moral-judgment', 'action-agree', 'action-legal', 'action-pressure', 'action-char-involved', 'action-hypothetical', 'situation', 'situation-short-id', 'rot', 'rot-id', 'rot-worker-id', 'breakdown-worker-id', 'n-characters', 'characters'],\n",
       "        num_rows: 233501\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = dataset.filter(lambda example: example['split'] == 'train')\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['area', 'm', 'split', 'rot-agree', 'rot-categorization', 'rot-moral-foundations', 'rot-char-targeting', 'rot-bad', 'rot-judgment', 'action', 'action-agency', 'action-moral-judgment', 'action-agree', 'action-legal', 'action-pressure', 'action-char-involved', 'action-hypothetical', 'situation', 'situation-short-id', 'rot', 'rot-id', 'rot-worker-id', 'breakdown-worker-id', 'n-characters', 'characters'],\n",
       "        num_rows: 29239\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = dataset.filter(lambda example: example['split'] == 'test')\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Distinct situations\"\"\"\n",
    "distinct_situations = set()\n",
    "\n",
    "def find_distinct_situations(example):\n",
    "    distinct_situations.add(example['situation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 1109/233501 [00:00<00:42, 5490.07 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 233501/233501 [00:34<00:00, 6720.30 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['area', 'm', 'split', 'rot-agree', 'rot-categorization', 'rot-moral-foundations', 'rot-char-targeting', 'rot-bad', 'rot-judgment', 'action', 'action-agency', 'action-moral-judgment', 'action-agree', 'action-legal', 'action-pressure', 'action-char-involved', 'action-hypothetical', 'situation', 'situation-short-id', 'rot', 'rot-id', 'rot-worker-id', 'breakdown-worker-id', 'n-characters', 'characters'],\n",
       "        num_rows: 233501\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.map(find_distinct_situations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_situations = list(distinct_situations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82685"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(distinct_situations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Distinct RoTs\"\"\"\n",
    "distinct_rots = set()\n",
    "\n",
    "def find_distinct_rots(example):\n",
    "    distinct_rots.add(example['rot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 233501/233501 [00:34<00:00, 6753.24 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['area', 'm', 'split', 'rot-agree', 'rot-categorization', 'rot-moral-foundations', 'rot-char-targeting', 'rot-bad', 'rot-judgment', 'action', 'action-agency', 'action-moral-judgment', 'action-agree', 'action-legal', 'action-pressure', 'action-char-involved', 'action-hypothetical', 'situation', 'situation-short-id', 'rot', 'rot-id', 'rot-worker-id', 'breakdown-worker-id', 'n-characters', 'characters'],\n",
       "        num_rows: 233501\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.map(find_distinct_rots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209600"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_rots = list(distinct_rots)\n",
    "len(distinct_rots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"RoTs for each situation\"\"\"\n",
    "rots_per_situation = {key:[] for key in distinct_situations}\n",
    "\n",
    "def rots_for_each_situation(example):\n",
    "    rots_per_situation[example['situation']].append(example['rot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 233501/233501 [00:36<00:00, 6452.06 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['area', 'm', 'split', 'rot-agree', 'rot-categorization', 'rot-moral-foundations', 'rot-char-targeting', 'rot-bad', 'rot-judgment', 'action', 'action-agency', 'action-moral-judgment', 'action-agree', 'action-legal', 'action-pressure', 'action-char-involved', 'action-hypothetical', 'situation', 'situation-short-id', 'rot', 'rot-id', 'rot-worker-id', 'breakdown-worker-id', 'n-characters', 'characters'],\n",
       "        num_rows: 233501\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.map(rots_for_each_situation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breaking up with my cheating ex to pursue someone I had caught feelings for whilst with her\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"You shouldn't cheat on others.\",\n",
       " \"It's good to go after someone you have feelings for.\",\n",
       " \"It's good to break up with someone that is cheating on you.\",\n",
       " \"It's good to break up with someone before you go after someone else.\"]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(distinct_situations[4])\n",
    "rots_per_situation[distinct_situations[4]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the train dataset for the binary classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_a = \"this is a sentence\"\n",
    "sentence_b = \"this is another sentence\"\n",
    "\n",
    "encoding = tokenizer(sentence_a, sentence_b, padding=\"max_length\", truncation=True)\n",
    "tokenizer.decode(encoding[\"input_ids\"])\n",
    "encoding.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def negative_examples(example):\n",
    "\n",
    "    negative_rot = None\n",
    "    #sample a negative RoT for the current situation\n",
    "    while negative_rot is None:\n",
    "        candidate_rot = random.choice(distinct_rots)\n",
    "        if candidate_rot not in rots_per_situation[example['situation']]:\n",
    "            negative_rot = candidate_rot\n",
    "\n",
    "    encoding = tokenizer(example['situation'], negative_rot, padding=\"max_length\", truncation=True)\n",
    "\n",
    "    encoding['labels'] = 0\n",
    "\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 233501/233501 [03:35<00:00, 1085.00 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 233501\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_dataset = train_dataset.map(negative_examples)\n",
    "negative_dataset = negative_dataset.select_columns(['input_ids', 'token_type_ids', 'attention_mask', 'labels']) #filter the columns\n",
    "negative_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_examples(example):\n",
    "    encoding = tokenizer(example['situation'], example['rot'], padding=\"max_length\", truncation=True)\n",
    "    encoding['labels'] = 1\n",
    "\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 233501/233501 [03:24<00:00, 1144.49 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 233501\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_dataset = train_dataset.map(positive_examples)\n",
    "positive_dataset = positive_dataset.select_columns(['input_ids', 'token_type_ids', 'attention_mask', 'labels']) #filter the columns\n",
    "positive_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 467002\n",
       "})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "bert_train_dataset = concatenate_datasets([negative_dataset['train'], positive_dataset['train']])\n",
    "bert_train_dataset = bert_train_dataset.shuffle(seed=42)\n",
    "bert_train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save BERT train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (3/3 shards): 100%|██████████| 467002/467002 [00:26<00:00, 17298.74 examples/s]\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/IAIS/gplepi/entero/data_social_norms/binary_classification_bert_train\"\n",
    "bert_train_dataset.save_to_disk(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Distinct situations\"\"\"\n",
    "distinct_situations = set()\n",
    "\n",
    "def find_distinct_situations(example):\n",
    "    distinct_situations.add(example['situation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 29239/29239 [00:04<00:00, 6785.99 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['area', 'm', 'split', 'rot-agree', 'rot-categorization', 'rot-moral-foundations', 'rot-char-targeting', 'rot-bad', 'rot-judgment', 'action', 'action-agency', 'action-moral-judgment', 'action-agree', 'action-legal', 'action-pressure', 'action-char-involved', 'action-hypothetical', 'situation', 'situation-short-id', 'rot', 'rot-id', 'rot-worker-id', 'breakdown-worker-id', 'n-characters', 'characters'],\n",
       "        num_rows: 29239\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.map(find_distinct_situations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10361"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_situations = list(distinct_situations)\n",
    "len(distinct_situations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Distinct RoTs\"\"\"\n",
    "distinct_rots = set()\n",
    "\n",
    "def find_distinct_rots(example):\n",
    "    distinct_rots.add(example['rot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 29239/29239 [00:04<00:00, 6767.49 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['area', 'm', 'split', 'rot-agree', 'rot-categorization', 'rot-moral-foundations', 'rot-char-targeting', 'rot-bad', 'rot-judgment', 'action', 'action-agency', 'action-moral-judgment', 'action-agree', 'action-legal', 'action-pressure', 'action-char-involved', 'action-hypothetical', 'situation', 'situation-short-id', 'rot', 'rot-id', 'rot-worker-id', 'breakdown-worker-id', 'n-characters', 'characters'],\n",
       "        num_rows: 29239\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.map(find_distinct_rots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28077"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_rots = list(distinct_rots)\n",
    "len(distinct_rots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"RoTs for each situation\"\"\"\n",
    "rots_per_situation = {key:[] for key in distinct_situations}\n",
    "\n",
    "def rots_for_each_situation(example):\n",
    "    rots_per_situation[example['situation']].append(example['rot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 29239/29239 [00:04<00:00, 6210.13 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['area', 'm', 'split', 'rot-agree', 'rot-categorization', 'rot-moral-foundations', 'rot-char-targeting', 'rot-bad', 'rot-judgment', 'action', 'action-agency', 'action-moral-judgment', 'action-agree', 'action-legal', 'action-pressure', 'action-char-involved', 'action-hypothetical', 'situation', 'situation-short-id', 'rot', 'rot-id', 'rot-worker-id', 'breakdown-worker-id', 'n-characters', 'characters'],\n",
       "        num_rows: 29239\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.map(rots_for_each_situation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the test dataset for binary classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def negative_examples(example):\n",
    "\n",
    "    negative_rot = None\n",
    "    #sample a negative RoT for the current situation\n",
    "    while negative_rot is None:\n",
    "        candidate_rot = random.choice(distinct_rots)\n",
    "        if candidate_rot not in rots_per_situation[example['situation']]:\n",
    "            negative_rot = candidate_rot\n",
    "\n",
    "    encoding = tokenizer(example['situation'], negative_rot, padding=\"max_length\", truncation=True)\n",
    "\n",
    "    encoding['labels'] = 0\n",
    "\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 29239/29239 [00:27<00:00, 1055.54 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 29239\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_dataset = test_dataset.map(negative_examples)\n",
    "negative_dataset = negative_dataset.select_columns(['input_ids', 'token_type_ids', 'attention_mask', 'labels']) #filter the columns\n",
    "negative_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_examples(example):\n",
    "    encoding = tokenizer(example['situation'], example['rot'], padding=\"max_length\", truncation=True)\n",
    "    encoding['labels'] = 1\n",
    "\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 29239/29239 [00:28<00:00, 1008.51 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 29239\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_dataset = test_dataset.map(positive_examples)\n",
    "positive_dataset = positive_dataset.select_columns(['input_ids', 'token_type_ids', 'attention_mask', 'labels']) #filter the columns\n",
    "positive_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 58478\n",
       "})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "bert_test_dataset = concatenate_datasets([negative_dataset['train'], positive_dataset['train']])\n",
    "bert_test_dataset = bert_test_dataset.shuffle(seed=42)\n",
    "bert_test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save BERT test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 58478/58478 [00:03<00:00, 17152.69 examples/s]\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/IAIS/gplepi/entero/data_social_norms/binary_classification_bert_test\"\n",
    "bert_test_dataset.save_to_disk(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classification BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load BERT train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "path_train = \"/home/IAIS/gplepi/entero/data_social_norms/binary_classification_bert_train\"\n",
    "path_test = \"/home/IAIS/gplepi/entero/data_social_norms/binary_classification_bert_test\"\n",
    "bert_train_dataset = datasets.load_from_disk(path_train)\n",
    "bert_test_dataset = datasets.load_from_disk(path_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"NOT-APPLIED\", 1: \"APPLIED\"}\n",
    "\n",
    "label2id = {\"NOT-APPLIED\": 0, \"APPLIED\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device('cuda:0')\n",
    "model = model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"output_social_norms\",\n",
    "    learning_rate=2e-5,\n",
    "    auto_find_batch_size=True,\n",
    "    num_train_epochs=3,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    save_steps=1000,\n",
    "    save_strategy=\"steps\",\n",
    "    metric_for_best_model='f1',\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "import evaluate\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    accuracy_score = accuracy.compute(predictions=predictions, references=labels)\n",
    "    precision_score = precision.compute(predictions=predictions, references=labels)\n",
    "    recall_score = recall.compute(predictions=predictions, references=labels)\n",
    "    f1_score = f1.compute(predictions=predictions, references=labels)\n",
    "    \n",
    "    return {\n",
    "        \"precision\": precision_score['precision'],\n",
    "        \"recall\": recall_score['recall'],\n",
    "        \"f1\": f1_score['f1'],\n",
    "        \"accuracy\": accuracy_score['accuracy'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=bert_train_dataset,\n",
    "    eval_dataset=bert_test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='635' max='43782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  635/43782 09:54 < 11:15:56, 1.06 it/s, Epoch 0.04/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entero_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
