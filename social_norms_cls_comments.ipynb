{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Comments Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>permalink</th>\n",
       "      <th>label</th>\n",
       "      <th>body</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>author_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>eamexog</td>\n",
       "      <td>/r/AmItheAsshole/comments/a1311q/aita_for_tell...</td>\n",
       "      <td>NTA</td>\n",
       "      <td>Uh absolutely NTA. These are really really hor...</td>\n",
       "      <td>a1311q</td>\n",
       "      <td>t2_2kabg9z7</td>\n",
       "      <td>xormun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>eameha5</td>\n",
       "      <td>/r/AmItheAsshole/comments/a1311q/aita_for_tell...</td>\n",
       "      <td>NTA</td>\n",
       "      <td>NTA. Ok sweetie no, hell no this is not your f...</td>\n",
       "      <td>a1311q</td>\n",
       "      <td>t2_1jrodkow</td>\n",
       "      <td>tkPuncake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>eamjnog</td>\n",
       "      <td>/r/AmItheAsshole/comments/a1311q/aita_for_tell...</td>\n",
       "      <td>NTA</td>\n",
       "      <td>NTA. My girlfriend has hypothyroidism and i kn...</td>\n",
       "      <td>a1311q</td>\n",
       "      <td>t2_14ub01</td>\n",
       "      <td>hawkbearpig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ef5kbsb</td>\n",
       "      <td>/r/AmItheAsshole/comments/akkcpn/aita_for_not_...</td>\n",
       "      <td>NTA</td>\n",
       "      <td>You're clearly NTA. Sorry about your homophobi...</td>\n",
       "      <td>akkcpn</td>\n",
       "      <td>t2_61b3s</td>\n",
       "      <td>sadsquash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ef5l208</td>\n",
       "      <td>/r/AmItheAsshole/comments/akkcpn/aita_for_not_...</td>\n",
       "      <td>NTA</td>\n",
       "      <td>NTA. And it will get better, I promise. You'll...</td>\n",
       "      <td>akkcpn</td>\n",
       "      <td>t2_xvrsh</td>\n",
       "      <td>SheketBevakaSTFU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530631</th>\n",
       "      <td>ei9ofvo</td>\n",
       "      <td>/r/AmItheAsshole/comments/azofrl/aita_for_not_...</td>\n",
       "      <td>YTA</td>\n",
       "      <td>NAH (a bit towards yta) OP. You found the wors...</td>\n",
       "      <td>azofrl</td>\n",
       "      <td>t2_16fctm</td>\n",
       "      <td>xAlois</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530636</th>\n",
       "      <td>ei9gkon</td>\n",
       "      <td>/r/AmItheAsshole/comments/azofrl/aita_for_not_...</td>\n",
       "      <td>NTA</td>\n",
       "      <td>NTA &amp;#x200B; but you handled it really poorly,...</td>\n",
       "      <td>azofrl</td>\n",
       "      <td>t2_dk4gojr</td>\n",
       "      <td>YoungDiscord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530637</th>\n",
       "      <td>ei9gl79</td>\n",
       "      <td>/r/AmItheAsshole/comments/azofrl/aita_for_not_...</td>\n",
       "      <td>NTA</td>\n",
       "      <td>NTA how are you the asshole? For like bigger b...</td>\n",
       "      <td>azofrl</td>\n",
       "      <td>t2_2xfoz1fv</td>\n",
       "      <td>Dark-_-Legacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530639</th>\n",
       "      <td>ei9gmpk</td>\n",
       "      <td>/r/AmItheAsshole/comments/azofrl/aita_for_not_...</td>\n",
       "      <td>NTA</td>\n",
       "      <td>NTA. Your girlfriend is overreacting. You don'...</td>\n",
       "      <td>azofrl</td>\n",
       "      <td>t2_15bdqt5w</td>\n",
       "      <td>Broken_Angel-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530660</th>\n",
       "      <td>ei9bv68</td>\n",
       "      <td>/r/AmItheAsshole/comments/azofrl/aita_for_not_...</td>\n",
       "      <td>YTA</td>\n",
       "      <td>YTA if it's that big of a problem, but her som...</td>\n",
       "      <td>azofrl</td>\n",
       "      <td>t2_21p0gvq6</td>\n",
       "      <td>op2mus_2357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>212687 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                          permalink label  \\\n",
       "13      eamexog  /r/AmItheAsshole/comments/a1311q/aita_for_tell...   NTA   \n",
       "14      eameha5  /r/AmItheAsshole/comments/a1311q/aita_for_tell...   NTA   \n",
       "16      eamjnog  /r/AmItheAsshole/comments/a1311q/aita_for_tell...   NTA   \n",
       "17      ef5kbsb  /r/AmItheAsshole/comments/akkcpn/aita_for_not_...   NTA   \n",
       "20      ef5l208  /r/AmItheAsshole/comments/akkcpn/aita_for_not_...   NTA   \n",
       "...         ...                                                ...   ...   \n",
       "530631  ei9ofvo  /r/AmItheAsshole/comments/azofrl/aita_for_not_...   YTA   \n",
       "530636  ei9gkon  /r/AmItheAsshole/comments/azofrl/aita_for_not_...   NTA   \n",
       "530637  ei9gl79  /r/AmItheAsshole/comments/azofrl/aita_for_not_...   NTA   \n",
       "530639  ei9gmpk  /r/AmItheAsshole/comments/azofrl/aita_for_not_...   NTA   \n",
       "530660  ei9bv68  /r/AmItheAsshole/comments/azofrl/aita_for_not_...   YTA   \n",
       "\n",
       "                                                     body parent_id  \\\n",
       "13      Uh absolutely NTA. These are really really hor...    a1311q   \n",
       "14      NTA. Ok sweetie no, hell no this is not your f...    a1311q   \n",
       "16      NTA. My girlfriend has hypothyroidism and i kn...    a1311q   \n",
       "17      You're clearly NTA. Sorry about your homophobi...    akkcpn   \n",
       "20      NTA. And it will get better, I promise. You'll...    akkcpn   \n",
       "...                                                   ...       ...   \n",
       "530631  NAH (a bit towards yta) OP. You found the wors...    azofrl   \n",
       "530636  NTA &#x200B; but you handled it really poorly,...    azofrl   \n",
       "530637  NTA how are you the asshole? For like bigger b...    azofrl   \n",
       "530639  NTA. Your girlfriend is overreacting. You don'...    azofrl   \n",
       "530660  YTA if it's that big of a problem, but her som...    azofrl   \n",
       "\n",
       "       author_fullname       author_name  \n",
       "13         t2_2kabg9z7            xormun  \n",
       "14         t2_1jrodkow         tkPuncake  \n",
       "16           t2_14ub01       hawkbearpig  \n",
       "17            t2_61b3s         sadsquash  \n",
       "20            t2_xvrsh  SheketBevakaSTFU  \n",
       "...                ...               ...  \n",
       "530631       t2_16fctm            xAlois  \n",
       "530636      t2_dk4gojr      YoungDiscord  \n",
       "530637     t2_2xfoz1fv     Dark-_-Legacy  \n",
       "530639     t2_15bdqt5w     Broken_Angel-  \n",
       "530660     t2_21p0gvq6       op2mus_2357  \n",
       "\n",
       "[212687 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "social_comments = pd.read_pickle('/home/IAIS/gplepi/entero/data_social_norms/social_comments_filtered.gzip', compression='gzip')\n",
    "social_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Any\n",
    "import string\n",
    "\n",
    "\"\"\"\n",
    "Text preprocessing: lowercase; remove punctuation; remove NTA_KEYWORDS, YTA_KEYWORDS and 'ampx200b', 'x200b', 'AITA', 'aita'\n",
    "\"\"\"\n",
    "\n",
    "class KeywordsCleaner:\n",
    "    def __init__(self) -> None:\n",
    "        # NTA YTA keywords\n",
    "        NTA_KEYWORDS = ['nta', 'nah', 'you are not the asshole', 'you\\'re not the asshole', 'u are not the asshole', 'u re not the asshole', \n",
    "                        'you re not the asshole', 'u\\'re not the asshole', 'not the asshole', 'not the ah', 'not asshole', 'not ah']\n",
    "        YTA_KEYWORDS = ['yta', 'you are the asshole', 'you\\'re the asshole', 'u are the asshole', 'u re the asshole', \n",
    "                        'you re the asshole', 'u\\'re the asshole', 'you the ah', 'you the asshole', 'u the asshole', 'u the ah']\n",
    "\n",
    "        keywords_rep = {'ampx200b': \"\", 'x200b': \"\", 'AITA': \"\", 'aita': \"\"}\n",
    "        \n",
    "        for key in NTA_KEYWORDS + YTA_KEYWORDS:\n",
    "            keywords_rep[key] = \"\"\n",
    "        keywords_rep = dict(sorted(keywords_rep.items(), key=lambda k: len(k[0]), reverse=True))\n",
    "\n",
    "        self.rep = dict((re.escape(k), v) for k, v in keywords_rep.items())\n",
    "        self.pattern = re.compile(\"|\".join(self.rep.keys()))\n",
    "\n",
    "    def __call__(self, text: str) -> str:\n",
    "        text = self.pattern.sub(lambda m: self.rep[re.escape(m.group(0))], text.lower())\n",
    "        return text.translate(str.maketrans('', '', string.punctuation))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTA &#x200B; but you handled it really poorly, like that was the absolute worst way in which you could have ever said it &#x200B; why not acknowledge that she's beautiful and sexy in her own way? make a lateral move that you know, wouldn't require you to directly say: I'm not attracted to you physically? because that would just open up a can of worms. &#x200B; well, you messed it up so now you have to fix it. &#x200B; You're not an asshole for having a personal body type preference, everyone has but you are an idiot for handling it the way you did, good luck with that.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'  but you handled it really poorly like that was the absolute worst way in which you could have ever said it  why not acknowledge that shes beautiful and sexy in her own way make a lateral move that you know wouldnt require you to directly say im not attracted to you physically because that would just open up a can of worms  well you messed it up so now you have to fix it  youre not an asshole for having a personal body type preference everyone has but you are an idiot for handling it the way you did good luck with that'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Example\"\"\"\n",
    "keywordsCleaner = KeywordsCleaner()\n",
    "\n",
    "print(social_comments[\"body\"].at[530636])\n",
    "keywordsCleaner(social_comments[\"body\"].at[530636])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>permalink</th>\n",
       "      <th>label</th>\n",
       "      <th>body</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>author_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>eamexog</td>\n",
       "      <td>/r/AmItheAsshole/comments/a1311q/aita_for_tell...</td>\n",
       "      <td>NTA</td>\n",
       "      <td>uh absolutely  these are really really horrid ...</td>\n",
       "      <td>a1311q</td>\n",
       "      <td>t2_2kabg9z7</td>\n",
       "      <td>xormun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>eameha5</td>\n",
       "      <td>/r/AmItheAsshole/comments/a1311q/aita_for_tell...</td>\n",
       "      <td>NTA</td>\n",
       "      <td>ok sweetie no hell no this is not your fault ...</td>\n",
       "      <td>a1311q</td>\n",
       "      <td>t2_1jrodkow</td>\n",
       "      <td>tkPuncake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>eamjnog</td>\n",
       "      <td>/r/AmItheAsshole/comments/a1311q/aita_for_tell...</td>\n",
       "      <td>NTA</td>\n",
       "      <td>my girlfriend has hypothyroidism and i know t...</td>\n",
       "      <td>a1311q</td>\n",
       "      <td>t2_14ub01</td>\n",
       "      <td>hawkbearpig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ef5kbsb</td>\n",
       "      <td>/r/AmItheAsshole/comments/akkcpn/aita_for_not_...</td>\n",
       "      <td>NTA</td>\n",
       "      <td>youre clearly  sorry about your homophobic fam...</td>\n",
       "      <td>akkcpn</td>\n",
       "      <td>t2_61b3s</td>\n",
       "      <td>sadsquash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ef5l208</td>\n",
       "      <td>/r/AmItheAsshole/comments/akkcpn/aita_for_not_...</td>\n",
       "      <td>NTA</td>\n",
       "      <td>and it will get better i promise youll make i...</td>\n",
       "      <td>akkcpn</td>\n",
       "      <td>t2_xvrsh</td>\n",
       "      <td>SheketBevakaSTFU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530631</th>\n",
       "      <td>ei9ofvo</td>\n",
       "      <td>/r/AmItheAsshole/comments/azofrl/aita_for_not_...</td>\n",
       "      <td>YTA</td>\n",
       "      <td>a bit towards  op you found the worst way to ...</td>\n",
       "      <td>azofrl</td>\n",
       "      <td>t2_16fctm</td>\n",
       "      <td>xAlois</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530636</th>\n",
       "      <td>ei9gkon</td>\n",
       "      <td>/r/AmItheAsshole/comments/azofrl/aita_for_not_...</td>\n",
       "      <td>NTA</td>\n",
       "      <td>but you handled it really poorly like that w...</td>\n",
       "      <td>azofrl</td>\n",
       "      <td>t2_dk4gojr</td>\n",
       "      <td>YoungDiscord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530637</th>\n",
       "      <td>ei9gl79</td>\n",
       "      <td>/r/AmItheAsshole/comments/azofrl/aita_for_not_...</td>\n",
       "      <td>NTA</td>\n",
       "      <td>how are  for like bigger boobs</td>\n",
       "      <td>azofrl</td>\n",
       "      <td>t2_2xfoz1fv</td>\n",
       "      <td>Dark-_-Legacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530639</th>\n",
       "      <td>ei9gmpk</td>\n",
       "      <td>/r/AmItheAsshole/comments/azofrl/aita_for_not_...</td>\n",
       "      <td>NTA</td>\n",
       "      <td>your girlfriend is overreacting you dont have...</td>\n",
       "      <td>azofrl</td>\n",
       "      <td>t2_15bdqt5w</td>\n",
       "      <td>Broken_Angel-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530660</th>\n",
       "      <td>ei9bv68</td>\n",
       "      <td>/r/AmItheAsshole/comments/azofrl/aita_for_not_...</td>\n",
       "      <td>YTA</td>\n",
       "      <td>if its that big of a problem but her some new...</td>\n",
       "      <td>azofrl</td>\n",
       "      <td>t2_21p0gvq6</td>\n",
       "      <td>op2mus_2357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>212687 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                          permalink label  \\\n",
       "13      eamexog  /r/AmItheAsshole/comments/a1311q/aita_for_tell...   NTA   \n",
       "14      eameha5  /r/AmItheAsshole/comments/a1311q/aita_for_tell...   NTA   \n",
       "16      eamjnog  /r/AmItheAsshole/comments/a1311q/aita_for_tell...   NTA   \n",
       "17      ef5kbsb  /r/AmItheAsshole/comments/akkcpn/aita_for_not_...   NTA   \n",
       "20      ef5l208  /r/AmItheAsshole/comments/akkcpn/aita_for_not_...   NTA   \n",
       "...         ...                                                ...   ...   \n",
       "530631  ei9ofvo  /r/AmItheAsshole/comments/azofrl/aita_for_not_...   YTA   \n",
       "530636  ei9gkon  /r/AmItheAsshole/comments/azofrl/aita_for_not_...   NTA   \n",
       "530637  ei9gl79  /r/AmItheAsshole/comments/azofrl/aita_for_not_...   NTA   \n",
       "530639  ei9gmpk  /r/AmItheAsshole/comments/azofrl/aita_for_not_...   NTA   \n",
       "530660  ei9bv68  /r/AmItheAsshole/comments/azofrl/aita_for_not_...   YTA   \n",
       "\n",
       "                                                     body parent_id  \\\n",
       "13      uh absolutely  these are really really horrid ...    a1311q   \n",
       "14       ok sweetie no hell no this is not your fault ...    a1311q   \n",
       "16       my girlfriend has hypothyroidism and i know t...    a1311q   \n",
       "17      youre clearly  sorry about your homophobic fam...    akkcpn   \n",
       "20       and it will get better i promise youll make i...    akkcpn   \n",
       "...                                                   ...       ...   \n",
       "530631   a bit towards  op you found the worst way to ...    azofrl   \n",
       "530636    but you handled it really poorly like that w...    azofrl   \n",
       "530637                     how are  for like bigger boobs    azofrl   \n",
       "530639   your girlfriend is overreacting you dont have...    azofrl   \n",
       "530660   if its that big of a problem but her some new...    azofrl   \n",
       "\n",
       "       author_fullname       author_name  \n",
       "13         t2_2kabg9z7            xormun  \n",
       "14         t2_1jrodkow         tkPuncake  \n",
       "16           t2_14ub01       hawkbearpig  \n",
       "17            t2_61b3s         sadsquash  \n",
       "20            t2_xvrsh  SheketBevakaSTFU  \n",
       "...                ...               ...  \n",
       "530631       t2_16fctm            xAlois  \n",
       "530636      t2_dk4gojr      YoungDiscord  \n",
       "530637     t2_2xfoz1fv     Dark-_-Legacy  \n",
       "530639     t2_15bdqt5w     Broken_Angel-  \n",
       "530660     t2_21p0gvq6       op2mus_2357  \n",
       "\n",
       "[212687 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Filter social comments\"\"\"\n",
    "keywordsCleaner = KeywordsCleaner()\n",
    "\n",
    "for i, row in social_comments.iterrows():\n",
    "    row['body'] = keywordsCleaner(row['body'])\n",
    "\n",
    "social_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'permalink', 'label', 'body', 'parent_id', 'author_fullname', 'author_name', '__index_level_0__'],\n",
       "    num_rows: 212687\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"From pandas to Huggingface Dataset\"\"\"\n",
    "from datasets import Dataset\n",
    "\n",
    "social_comments_dataset = Dataset.from_pandas(social_comments)\n",
    "social_comments_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/212687 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212687/212687 [00:09<00:00, 21853.93 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NTA': 150040, 'YTA': 62647}\n",
      "NTA: 0.7054497924179663 \n",
      "YTA: 0.2945502075820337 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Analyze the data\"\"\"\n",
    "data_distribution = {'NTA': 0, 'YTA': 0}\n",
    "\n",
    "def compute_data_distribution(example):\n",
    "    data_distribution[example['label']] += 1\n",
    "\n",
    "social_comments_dataset.map(compute_data_distribution)\n",
    "\n",
    "print(data_distribution)\n",
    "print(f\"NTA: {data_distribution['NTA'] / sum(data_distribution.values())} \")\n",
    "print(f\"YTA: {data_distribution['YTA'] / sum(data_distribution.values())} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'permalink', 'label', 'body', 'parent_id', 'author_fullname', 'author_name', '__index_level_0__'],\n",
       "        num_rows: 170149\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'permalink', 'label', 'body', 'parent_id', 'author_fullname', 'author_name', '__index_level_0__'],\n",
       "        num_rows: 21269\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['id', 'permalink', 'label', 'body', 'parent_id', 'author_fullname', 'author_name', '__index_level_0__'],\n",
       "        num_rows: 21269\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "\"\"\"80-10-10 split\"\"\"\n",
    "# 80% train, 20% test + validation\n",
    "train_testvalid = social_comments_dataset.train_test_split(test_size=0.2, seed=SEED)\n",
    "# Split the 20% test + valid in half test, half valid\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5, seed=SEED)\n",
    "\n",
    "social_comments_dataset = DatasetDict({\n",
    "    'train': train_testvalid['train'],\n",
    "    'test': test_valid['test'],\n",
    "    'val': test_valid['train']})\n",
    "\n",
    "social_comments_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"NTA\", 1: \"YTA\"}\n",
    "\n",
    "label2id = {\"NTA\": 0, \"YTA\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# social-chemestry-101 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['area', 'm', 'split', 'rot-agree', 'rot-categorization', 'rot-moral-foundations', 'rot-char-targeting', 'rot-bad', 'rot-judgment', 'action', 'action-agency', 'action-moral-judgment', 'action-agree', 'action-legal', 'action-pressure', 'action-char-involved', 'action-hypothetical', 'situation', 'situation-short-id', 'rot', 'rot-id', 'rot-worker-id', 'breakdown-worker-id', 'n-characters', 'characters'],\n",
       "        num_rows: 355922\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "social_chemestry_dataset = load_dataset(\"metaeval/social-chemestry-101\")\n",
    "social_chemestry_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "situationId_to_situation = {}\n",
    "situationId_to_ROT_moral_foundations = defaultdict(set)\n",
    "situationId_to_ROT_categories = defaultdict(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 355922/355922 [00:44<00:00, 7991.88 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['area', 'm', 'split', 'rot-agree', 'rot-categorization', 'rot-moral-foundations', 'rot-char-targeting', 'rot-bad', 'rot-judgment', 'action', 'action-agency', 'action-moral-judgment', 'action-agree', 'action-legal', 'action-pressure', 'action-char-involved', 'action-hypothetical', 'situation', 'situation-short-id', 'rot', 'rot-id', 'rot-worker-id', 'breakdown-worker-id', 'n-characters', 'characters'],\n",
       "        num_rows: 355922\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mapping_from_situationId(example):\n",
    "    situation_id = example['situation-short-id'].split(\"/\")[-1]\n",
    "\n",
    "    situationId_to_situation[situation_id] = example['situation']\n",
    "    if example['rot-moral-foundations'] is not None:\n",
    "        situationId_to_ROT_moral_foundations[situation_id].add(example['rot-moral-foundations'])\n",
    "    if example['rot-categorization'] is not None:\n",
    "        situationId_to_ROT_categories[situation_id].add(example['rot-categorization'])\n",
    "\n",
    "social_chemestry_dataset.map(mapping_from_situationId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'care-harm|fairness-cheating',\n",
       " 'care-harm|loyalty-betrayal',\n",
       " 'fairness-cheating',\n",
       " 'loyalty-betrayal'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "situationId_to_ROT_moral_foundations['adwxny']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loyalty-betrayal. care-harm|fairness-cheating. fairness-cheating. care-harm|loyalty-betrayal'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'. '.join(situationId_to_ROT_moral_foundations['adwxny'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization for p(y|c) -> Only comments texts (filtered from NTA/YTA tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\"\"\"Tokenize the data\"\"\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize_data_only_comments(example):\n",
    "    encoding = tokenizer(example['body'], padding=\"max_length\", truncation=True)\n",
    "    encoding['labels'] = label2id[ example['label'] ]\n",
    "\n",
    "    return encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization for p(y|c,s) -> Situation Text + tokenizer.sep_token + comments text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\"\"\"Tokenize the data\"\"\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize_data_situations_comments(example):\n",
    "    situation = situationId_to_situation[example['parent_id']]\n",
    "    \n",
    "    encoding = tokenizer(situation, example['body'], padding=\"max_length\", truncation=True)\n",
    "    encoding['labels'] = label2id[ example['label'] ]\n",
    "\n",
    "    return encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization for p(y|c,rot) -> Rot-moral-foundations +  tokenizer.sep_token + comments text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\"\"\"Tokenize the data\"\"\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize_data_moralFoundations_comments(example):\n",
    "    rots = '. '.join(situationId_to_ROT_moral_foundations[example['parent_id']])\n",
    "    \n",
    "    encoding = tokenizer(rots, example['body'], padding=\"max_length\", truncation=True)\n",
    "    encoding['labels'] = label2id[ example['label'] ]\n",
    "\n",
    "    return encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization for p(y|c,rot) -> Rot-categories +  tokenizer.sep_token + comments text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\"\"\"Tokenize the data\"\"\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize_data_categories_comments(example):\n",
    "    rots = '. '.join(situationId_to_ROT_categories[example['parent_id']])\n",
    "    \n",
    "    encoding = tokenizer(rots, example['body'], padding=\"max_length\", truncation=True)\n",
    "    encoding['labels'] = label2id[ example['label'] ]\n",
    "\n",
    "    return encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization for p(y|c,a) -> Author ID + Comment text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\"\"\"Tokenize the data\"\"\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize_data_authorId_comments(example):\n",
    "\n",
    "    text = example['id'] + \". \" + example['body'] \n",
    "\n",
    "    encoding = tokenizer(text, padding=\"max_length\", truncation=True)\n",
    "    encoding['labels'] = label2id[ example['label'] ]\n",
    "\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization for p(y|c,s,a) -> situation + tokenizer.sep_token + (Author ID + Comment text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\"\"\"Tokenize the data\"\"\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize_data_situation_authorId_comments(example):\n",
    "    situation = situationId_to_situation[example['parent_id']]\n",
    "    text = example['id'] + \". \" + example['body'] \n",
    "\n",
    "    encoding = tokenizer(text, situation, padding=\"max_length\", truncation=True)\n",
    "    encoding['labels'] = label2id[ example['label'] ]\n",
    "\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Evaluation\"\"\"\n",
    "from transformers import DataCollatorWithPadding\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "f1 = evaluate.load(\"f1\", average='macro')\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    accuracy_score = accuracy.compute(predictions=predictions, references=labels)\n",
    "    precision_score = precision.compute(predictions=predictions, references=labels)\n",
    "    recall_score = recall.compute(predictions=predictions, references=labels)\n",
    "    f1_score = f1.compute(predictions=predictions, references=labels)\n",
    "    \n",
    "    return {\n",
    "        \"precision\": precision_score['precision'],\n",
    "        \"recall\": recall_score['recall'],\n",
    "        \"f1\": f1_score['f1'],\n",
    "        \"accuracy\": accuracy_score['accuracy'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT model for p(y|c) -> only comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170149/170149 [01:52<00:00, 1517.50 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21269/21269 [00:14<00:00, 1452.08 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21269/21269 [00:14<00:00, 1441.29 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 170149\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 21269\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 21269\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Tokenize the dataset\"\"\"\n",
    "tokenized_dataset = social_comments_dataset.map(tokenize_data_only_comments)\n",
    "\n",
    "tokenized_dataset = tokenized_dataset.select_columns(['input_ids', 'attention_mask', 'labels'])\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"output_social_norms/bert_comments_classification\",\n",
    "    learning_rate=2e-5,\n",
    "    #auto_find_batch_size=True,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    save_steps=1000,\n",
    "    save_strategy=\"steps\",\n",
    "    metric_for_best_model='f1',\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"wandb\",\n",
    "    push_to_hub=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['val'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgjergjplepi12\u001b[0m (\u001b[33msocial-chem-101-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/IAIS/gplepi/entero/wandb/run-20240121_163555-0fyeemr9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/social-chem-101-team/huggingface/runs/0fyeemr9' target=\"_blank\">confused-grass-46</a></strong> to <a href='https://wandb.ai/social-chem-101-team/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/social-chem-101-team/huggingface' target=\"_blank\">https://wandb.ai/social-chem-101-team/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/social-chem-101-team/huggingface/runs/0fyeemr9' target=\"_blank\">https://wandb.ai/social-chem-101-team/huggingface/runs/0fyeemr9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3990' max='3990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3990/3990 1:53:25, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.406300</td>\n",
       "      <td>0.370032</td>\n",
       "      <td>0.784541</td>\n",
       "      <td>0.584026</td>\n",
       "      <td>0.669594</td>\n",
       "      <td>0.833749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.325300</td>\n",
       "      <td>0.346103</td>\n",
       "      <td>0.797600</td>\n",
       "      <td>0.639120</td>\n",
       "      <td>0.709619</td>\n",
       "      <td>0.849123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.289600</td>\n",
       "      <td>0.342456</td>\n",
       "      <td>0.768642</td>\n",
       "      <td>0.703993</td>\n",
       "      <td>0.734899</td>\n",
       "      <td>0.853496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3990, training_loss=0.34324239477477875, metrics={'train_runtime': 6816.8272, 'train_samples_per_second': 74.88, 'train_steps_per_second': 0.585, 'total_flos': 6.761758624175923e+16, 'train_loss': 0.34324239477477875, 'epoch': 3.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90     14961\n",
      "           1       0.77      0.72      0.74      6308\n",
      "\n",
      "    accuracy                           0.85     21269\n",
      "   macro avg       0.83      0.81      0.82     21269\n",
      "weighted avg       0.85      0.85      0.85     21269\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Testing\"\"\"\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model_path = \"/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification\"\n",
    "\n",
    "finetuned_model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=finetuned_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['val'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "\"\"\"Predict\"\"\"\n",
    "predictions_output = trainer.predict(tokenized_dataset['test'])\n",
    "\n",
    "\n",
    "preds = np.argmax(predictions_output.predictions, axis=-1)\n",
    "labels = predictions_output.label_ids\n",
    "print(classification_report(y_true=labels, y_pred=preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT model for p(y|c,s) -> situations and comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170149/170149 [02:04<00:00, 1371.26 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21269/21269 [00:15<00:00, 1334.15 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21269/21269 [00:15<00:00, 1349.91 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 170149\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 21269\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 21269\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Tokenize the data\"\"\"\n",
    "tokenized_dataset = social_comments_dataset.map(tokenize_data_situations_comments)\n",
    "\n",
    "tokenized_dataset = tokenized_dataset.select_columns(['input_ids', 'attention_mask', 'labels'])\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"output_social_norms/bert_comments_classification_situations_and_comments\",\n",
    "    learning_rate=2e-5,\n",
    "    #auto_find_batch_size=True,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    save_steps=1000,\n",
    "    save_strategy=\"steps\",\n",
    "    metric_for_best_model='f1',\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"wandb\",\n",
    "    push_to_hub=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['val'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgjergjplepi12\u001b[0m (\u001b[33msocial-chem-101-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/IAIS/gplepi/entero/wandb/run-20240116_192311-fbh2zf2u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/social-chem-101-team/huggingface/runs/fbh2zf2u' target=\"_blank\">sparkling-grass-29</a></strong> to <a href='https://wandb.ai/social-chem-101-team/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/social-chem-101-team/huggingface' target=\"_blank\">https://wandb.ai/social-chem-101-team/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/social-chem-101-team/huggingface/runs/fbh2zf2u' target=\"_blank\">https://wandb.ai/social-chem-101-team/huggingface/runs/fbh2zf2u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5319' max='5319' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5319/5319 2:30:47, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.369800</td>\n",
       "      <td>0.318699</td>\n",
       "      <td>0.822873</td>\n",
       "      <td>0.673187</td>\n",
       "      <td>0.740542</td>\n",
       "      <td>0.863933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.278800</td>\n",
       "      <td>0.273159</td>\n",
       "      <td>0.813627</td>\n",
       "      <td>0.794132</td>\n",
       "      <td>0.803761</td>\n",
       "      <td>0.888147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.236200</td>\n",
       "      <td>0.254236</td>\n",
       "      <td>0.809449</td>\n",
       "      <td>0.835045</td>\n",
       "      <td>0.822047</td>\n",
       "      <td>0.895717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.199900</td>\n",
       "      <td>0.247678</td>\n",
       "      <td>0.815281</td>\n",
       "      <td>0.845314</td>\n",
       "      <td>0.830026</td>\n",
       "      <td>0.900136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.188500</td>\n",
       "      <td>0.241619</td>\n",
       "      <td>0.832551</td>\n",
       "      <td>0.837979</td>\n",
       "      <td>0.835256</td>\n",
       "      <td>0.904650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5319, training_loss=0.27156329240133764, metrics={'train_runtime': 9059.5998, 'train_samples_per_second': 56.343, 'train_steps_per_second': 0.587, 'total_flos': 6.761758624175923e+16, 'train_loss': 0.27156329240133764, 'epoch': 3.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     14961\n",
      "           1       0.83      0.83      0.83      6308\n",
      "\n",
      "    accuracy                           0.90     21269\n",
      "   macro avg       0.88      0.88      0.88     21269\n",
      "weighted avg       0.90      0.90      0.90     21269\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Testing\"\"\"\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model_path = \"/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification_situations_and_comments\"\n",
    "\n",
    "finetuned_model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=finetuned_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['val'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "\"\"\"Predict\"\"\"\n",
    "predictions_output = trainer.predict(tokenized_dataset['test'])\n",
    "\n",
    "\n",
    "preds = np.argmax(predictions_output.predictions, axis=-1)\n",
    "labels = predictions_output.label_ids\n",
    "print(classification_report(y_true=labels, y_pred=preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT model for p(y|c,rot) -> ROT-moral_foundations and comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170149/170149 [02:02<00:00, 1386.90 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21269/21269 [00:15<00:00, 1415.74 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21269/21269 [00:15<00:00, 1372.85 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 170149\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 21269\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 21269\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Tokenize the data\"\"\"\n",
    "tokenized_dataset = social_comments_dataset.map(tokenize_data_moralFoundations_comments)\n",
    "\n",
    "tokenized_dataset = tokenized_dataset.select_columns(['input_ids', 'attention_mask', 'labels'])\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"output_social_norms/bert_comments_classification_rot-moralFoundations_and_comments\",\n",
    "    learning_rate=2e-5,\n",
    "    #auto_find_batch_size=True,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    save_steps=1000,\n",
    "    save_strategy=\"steps\",\n",
    "    metric_for_best_model='f1',\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"wandb\",\n",
    "    push_to_hub=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['val'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgjergjplepi12\u001b[0m (\u001b[33msocial-chem-101-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/IAIS/gplepi/entero/wandb/run-20240116_225405-zf1so60u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/social-chem-101-team/huggingface/runs/zf1so60u' target=\"_blank\">ethereal-shadow-30</a></strong> to <a href='https://wandb.ai/social-chem-101-team/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/social-chem-101-team/huggingface' target=\"_blank\">https://wandb.ai/social-chem-101-team/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/social-chem-101-team/huggingface/runs/zf1so60u' target=\"_blank\">https://wandb.ai/social-chem-101-team/huggingface/runs/zf1so60u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5319' max='5319' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5319/5319 2:30:30, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.426600</td>\n",
       "      <td>0.387951</td>\n",
       "      <td>0.783579</td>\n",
       "      <td>0.538223</td>\n",
       "      <td>0.638129</td>\n",
       "      <td>0.823922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.352700</td>\n",
       "      <td>0.345055</td>\n",
       "      <td>0.759051</td>\n",
       "      <td>0.683456</td>\n",
       "      <td>0.719273</td>\n",
       "      <td>0.846114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.310900</td>\n",
       "      <td>0.335037</td>\n",
       "      <td>0.764696</td>\n",
       "      <td>0.712469</td>\n",
       "      <td>0.737659</td>\n",
       "      <td>0.853825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.274900</td>\n",
       "      <td>0.334269</td>\n",
       "      <td>0.762955</td>\n",
       "      <td>0.727139</td>\n",
       "      <td>0.744617</td>\n",
       "      <td>0.856129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.333623</td>\n",
       "      <td>0.774019</td>\n",
       "      <td>0.723553</td>\n",
       "      <td>0.747936</td>\n",
       "      <td>0.859326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5319, training_loss=0.33911535295693357, metrics={'train_runtime': 9041.3826, 'train_samples_per_second': 56.457, 'train_steps_per_second': 0.588, 'total_flos': 6.761758624175923e+16, 'train_loss': 0.33911535295693357, 'epoch': 3.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89     14961\n",
      "           1       0.76      0.73      0.74      6308\n",
      "\n",
      "    accuracy                           0.85     21269\n",
      "   macro avg       0.82      0.82      0.82     21269\n",
      "weighted avg       0.85      0.85      0.85     21269\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model_path = \"/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification_rot-moralFoundations_and_comments\"\n",
    "\n",
    "finetuned_model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=finetuned_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['val'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "\"\"\"Predict\"\"\"\n",
    "predictions_output = trainer.predict(tokenized_dataset['test'])\n",
    "\n",
    "\n",
    "preds = np.argmax(predictions_output.predictions, axis=-1)\n",
    "labels = predictions_output.label_ids\n",
    "print(classification_report(y_true=labels, y_pred=preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT model for p(y|c,rot) -> ROT-categories and comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170149/170149 [02:02<00:00, 1383.91 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21269/21269 [00:15<00:00, 1387.06 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21269/21269 [00:15<00:00, 1389.55 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 170149\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 21269\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 21269\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Tokenize the data\"\"\"\n",
    "tokenized_dataset = social_comments_dataset.map(tokenize_data_categories_comments)\n",
    "\n",
    "tokenized_dataset = tokenized_dataset.select_columns(['input_ids', 'attention_mask', 'labels'])\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"output_social_norms/bert_comments_classification_rot-categories_and_comments\",\n",
    "    learning_rate=2e-5,\n",
    "    #auto_find_batch_size=True,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    save_steps=1000,\n",
    "    save_strategy=\"steps\",\n",
    "    metric_for_best_model='f1',\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"wandb\",\n",
    "    push_to_hub=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['val'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgjergjplepi12\u001b[0m (\u001b[33msocial-chem-101-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/IAIS/gplepi/entero/wandb/run-20240117_013825-x428g28m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/social-chem-101-team/huggingface/runs/x428g28m' target=\"_blank\">bright-butterfly-31</a></strong> to <a href='https://wandb.ai/social-chem-101-team/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/social-chem-101-team/huggingface' target=\"_blank\">https://wandb.ai/social-chem-101-team/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/social-chem-101-team/huggingface/runs/x428g28m' target=\"_blank\">https://wandb.ai/social-chem-101-team/huggingface/runs/x428g28m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5319' max='5319' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5319/5319 2:30:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.437900</td>\n",
       "      <td>0.398375</td>\n",
       "      <td>0.770591</td>\n",
       "      <td>0.539853</td>\n",
       "      <td>0.634908</td>\n",
       "      <td>0.820913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.363900</td>\n",
       "      <td>0.356032</td>\n",
       "      <td>0.759506</td>\n",
       "      <td>0.660962</td>\n",
       "      <td>0.706815</td>\n",
       "      <td>0.841836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.318300</td>\n",
       "      <td>0.336743</td>\n",
       "      <td>0.777654</td>\n",
       "      <td>0.685249</td>\n",
       "      <td>0.728533</td>\n",
       "      <td>0.852696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.279900</td>\n",
       "      <td>0.341323</td>\n",
       "      <td>0.752298</td>\n",
       "      <td>0.733659</td>\n",
       "      <td>0.742862</td>\n",
       "      <td>0.853496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.265400</td>\n",
       "      <td>0.341592</td>\n",
       "      <td>0.740406</td>\n",
       "      <td>0.748492</td>\n",
       "      <td>0.744427</td>\n",
       "      <td>0.851756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5319, training_loss=0.34635972913931046, metrics={'train_runtime': 9014.7744, 'train_samples_per_second': 56.623, 'train_steps_per_second': 0.59, 'total_flos': 6.761758624175923e+16, 'train_loss': 0.34635972913931046, 'epoch': 3.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Testing\"\"\"\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_path = \"/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification_rot-categories_and_comments\"\n",
    "\n",
    "finetuned_model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=finetuned_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['val'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-2.287483  ,  2.1564565 ],\n",
       "       [-2.7786372 ,  2.615933  ],\n",
       "       [ 3.6511924 , -3.284743  ],\n",
       "       ...,\n",
       "       [ 2.7265818 , -2.4175289 ],\n",
       "       [ 2.183299  , -1.9042403 ],\n",
       "       [ 0.7427094 , -0.52996004]], dtype=float32), label_ids=array([0, 1, 0, ..., 0, 0, 0]), metrics={'test_loss': 0.3509385287761688, 'test_precision': 0.7423022264329702, 'test_recall': 0.7452441344324667, 'test_f1': 0.7437702713392929, 'test_accuracy': 0.8477126334101274, 'test_runtime': 139.0999, 'test_samples_per_second': 152.905, 'test_steps_per_second': 1.596})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_output = trainer.predict(tokenized_dataset['test'])\n",
    "predictions_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89     14961\n",
      "           1       0.74      0.75      0.74      6308\n",
      "\n",
      "    accuracy                           0.85     21269\n",
      "   macro avg       0.82      0.82      0.82     21269\n",
      "weighted avg       0.85      0.85      0.85     21269\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "preds = np.argmax(predictions_output.predictions, axis=-1)\n",
    "labels = predictions_output.label_ids\n",
    "print(classification_report(y_true=labels, y_pred=preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT model for p(y|c,a) -> Author ID and Comment text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170149/170149 [02:00<00:00, 1417.20 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21269/21269 [00:14<00:00, 1474.15 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21269/21269 [00:14<00:00, 1459.20 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 170149\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 21269\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 21269\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Tokenize the data\"\"\"\n",
    "tokenized_dataset = social_comments_dataset.map(tokenize_data_authorId_comments)\n",
    "\n",
    "tokenized_dataset = tokenized_dataset.select_columns(['input_ids', 'attention_mask', 'labels'])\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"output_social_norms/bert_comments_classification_authorId_and_comments\",\n",
    "    learning_rate=2e-5,\n",
    "    #auto_find_batch_size=True,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    save_steps=1000,\n",
    "    save_strategy=\"steps\",\n",
    "    metric_for_best_model='f1',\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"wandb\",\n",
    "    push_to_hub=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['val'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/IAIS/gplepi/entero/wandb/run-20240118_121747-tat19fbf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/social-chem-101-team/huggingface/runs/tat19fbf' target=\"_blank\">whole-field-32</a></strong> to <a href='https://wandb.ai/social-chem-101-team/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/social-chem-101-team/huggingface' target=\"_blank\">https://wandb.ai/social-chem-101-team/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/social-chem-101-team/huggingface/runs/tat19fbf' target=\"_blank\">https://wandb.ai/social-chem-101-team/huggingface/runs/tat19fbf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5319' max='5319' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5319/5319 2:29:51, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.423300</td>\n",
       "      <td>0.384240</td>\n",
       "      <td>0.790490</td>\n",
       "      <td>0.547351</td>\n",
       "      <td>0.646827</td>\n",
       "      <td>0.827589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.349400</td>\n",
       "      <td>0.347369</td>\n",
       "      <td>0.735421</td>\n",
       "      <td>0.696822</td>\n",
       "      <td>0.715601</td>\n",
       "      <td>0.840237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.307900</td>\n",
       "      <td>0.335660</td>\n",
       "      <td>0.754814</td>\n",
       "      <td>0.715566</td>\n",
       "      <td>0.734667</td>\n",
       "      <td>0.850910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.271300</td>\n",
       "      <td>0.334885</td>\n",
       "      <td>0.757336</td>\n",
       "      <td>0.732029</td>\n",
       "      <td>0.744467</td>\n",
       "      <td>0.855047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.255500</td>\n",
       "      <td>0.335809</td>\n",
       "      <td>0.761985</td>\n",
       "      <td>0.735778</td>\n",
       "      <td>0.748652</td>\n",
       "      <td>0.857492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5319, training_loss=0.3343056802306773, metrics={'train_runtime': 9011.2021, 'train_samples_per_second': 56.646, 'train_steps_per_second': 0.59, 'total_flos': 6.761758624175923e+16, 'train_loss': 0.3343056802306773, 'epoch': 3.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90     14961\n",
      "           1       0.77      0.74      0.75      6308\n",
      "\n",
      "    accuracy                           0.86     21269\n",
      "   macro avg       0.83      0.82      0.83     21269\n",
      "weighted avg       0.85      0.86      0.85     21269\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Testing\"\"\"\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model_path = \"/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification_authorId_and_comments\"\n",
    "\n",
    "finetuned_model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=finetuned_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['val'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "\"\"\"Predict\"\"\"\n",
    "predictions_output = trainer.predict(tokenized_dataset['test'])\n",
    "\n",
    "\n",
    "preds = np.argmax(predictions_output.predictions, axis=-1)\n",
    "labels = predictions_output.label_ids\n",
    "print(classification_report(y_true=labels, y_pred=preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT model for p(y|c,s,a) -> situation and Author ID and Comment text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170149/170149 [02:06<00:00, 1347.95 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21269/21269 [00:15<00:00, 1362.44 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21269/21269 [00:15<00:00, 1368.59 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 170149\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 21269\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 21269\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Tokenize the data\"\"\"\n",
    "tokenized_dataset = social_comments_dataset.map(tokenize_data_situation_authorId_comments)\n",
    "\n",
    "tokenized_dataset = tokenized_dataset.select_columns(['input_ids', 'attention_mask', 'labels'])\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"output_social_norms/bert_comments_classification_situations_authorId_and_comments\",\n",
    "    learning_rate=2e-5,\n",
    "    #auto_find_batch_size=True,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    save_steps=1000,\n",
    "    save_strategy=\"steps\",\n",
    "    metric_for_best_model='f1',\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"wandb\",\n",
    "    push_to_hub=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['val'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgjergjplepi12\u001b[0m (\u001b[33msocial-chem-101-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/IAIS/gplepi/entero/wandb/run-20240118_153025-bs6qr0p1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/social-chem-101-team/huggingface/runs/bs6qr0p1' target=\"_blank\">rural-bird-33</a></strong> to <a href='https://wandb.ai/social-chem-101-team/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/social-chem-101-team/huggingface' target=\"_blank\">https://wandb.ai/social-chem-101-team/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/social-chem-101-team/huggingface/runs/bs6qr0p1' target=\"_blank\">https://wandb.ai/social-chem-101-team/huggingface/runs/bs6qr0p1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5319' max='5319' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5319/5319 2:29:09, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.376700</td>\n",
       "      <td>0.328648</td>\n",
       "      <td>0.838625</td>\n",
       "      <td>0.628525</td>\n",
       "      <td>0.718532</td>\n",
       "      <td>0.857962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.287200</td>\n",
       "      <td>0.275822</td>\n",
       "      <td>0.823684</td>\n",
       "      <td>0.765281</td>\n",
       "      <td>0.793409</td>\n",
       "      <td>0.885044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.243000</td>\n",
       "      <td>0.259722</td>\n",
       "      <td>0.820581</td>\n",
       "      <td>0.805868</td>\n",
       "      <td>0.813158</td>\n",
       "      <td>0.893178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.202200</td>\n",
       "      <td>0.256249</td>\n",
       "      <td>0.818794</td>\n",
       "      <td>0.832274</td>\n",
       "      <td>0.825479</td>\n",
       "      <td>0.898491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.192300</td>\n",
       "      <td>0.252660</td>\n",
       "      <td>0.825540</td>\n",
       "      <td>0.834556</td>\n",
       "      <td>0.830024</td>\n",
       "      <td>0.901406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5319, training_loss=0.27660126891389875, metrics={'train_runtime': 8960.0337, 'train_samples_per_second': 56.969, 'train_steps_per_second': 0.594, 'total_flos': 6.761758624175923e+16, 'train_loss': 0.27660126891389875, 'epoch': 3.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/IAIS/gplepi/anaconda3/envs/entero_env/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93     14961\n",
      "           1       0.82      0.83      0.83      6308\n",
      "\n",
      "    accuracy                           0.90     21269\n",
      "   macro avg       0.87      0.88      0.88     21269\n",
      "weighted avg       0.90      0.90      0.90     21269\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Testing\"\"\"\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model_path = \"/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification_situations_authorId_and_comments\"\n",
    "\n",
    "finetuned_model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=finetuned_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['val'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "\"\"\"Predict\"\"\"\n",
    "predictions_output = trainer.predict(tokenized_dataset['test'])\n",
    "\n",
    "\n",
    "preds = np.argmax(predictions_output.predictions, axis=-1)\n",
    "labels = predictions_output.label_ids\n",
    "print(classification_report(y_true=labels, y_pred=preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If it's for your best, than do not worry about it. -> [{'label': 'NTA', 'score': 0.9908214807510376}]\n",
      "You shouldn't have done that, it's not allowed. -> [{'label': 'NTA', 'score': 0.5540988445281982}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Only comments\"\"\"\n",
    "\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "model_path = '/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification'\n",
    "\n",
    "nta_comment = \"If it's for your best, than do not worry about it.\"\n",
    "yta_comment = \"You shouldn't have done that, it's not allowed.\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "clf = pipeline(\"text-classification\", model=model_path, tokenizer=tokenizer)\n",
    "\n",
    "answer = clf(nta_comment)\n",
    "print(f\"{nta_comment} -> {answer}\")\n",
    "\n",
    "answer = clf(yta_comment)\n",
    "print(f\"{yta_comment} -> {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The situations is: Want to study abroad, but feel bad leaving my country.\n",
      "The comments:\n",
      "If it's for your best, than do not worry about it. -> [{'label': 'NTA', 'score': 0.9957548379898071}]\n",
      "You shouldn't have done that, it's not good behaviour. -> [{'label': 'NTA', 'score': 0.9957548379898071}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Situations and comments\"\"\"\n",
    "\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "model_path = '/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification_situations_and_comments'\n",
    "\n",
    "situation = \"Want to study abroad, but feel bad leaving my country.\"\n",
    "nta_comment = \"If it's for your best, than do not worry about it.\"\n",
    "yta_comment = \"You shouldn't have done that, it's not good behaviour.\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "clf = pipeline(\"text-classification\", model=model_path, tokenizer=tokenizer)\n",
    "\n",
    "print(f\"The situations is: {situation}\")\n",
    "print(\"The comments:\")\n",
    "\n",
    "answer = clf(situation + \" \" + tokenizer.sep_token + \" \" + nta_comment)\n",
    "print(f\"{nta_comment} -> {answer}\")\n",
    "\n",
    "answer = clf(situation + \" \" + tokenizer.sep_token + \" \" + nta_comment)\n",
    "print(f\"{yta_comment} -> {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If it's for your best, than do not worry about it. -> [{'label': 'NTA', 'score': 0.992794930934906}]\n",
      "You shouldn't have done that, it's not allowed. -> [{'label': 'YTA', 'score': 0.5742753148078918}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"rot-moralFoundations and comments\"\"\"\n",
    "\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "model_path = '/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification_rot-moralFoundations_and_comments'\n",
    "\n",
    "rot_moralFoundation = 'loyalty-betrayal'\n",
    "nta_comment = \"If it's for your best, than do not worry about it.\"\n",
    "yta_comment = \"You shouldn't have done that, it's not allowed.\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "clf = pipeline(\"text-classification\", model=model_path, tokenizer=tokenizer)\n",
    "\n",
    "answer = clf(rot_moralFoundation + \" \" + tokenizer.sep_token + \" \" + nta_comment)\n",
    "print(f\"{nta_comment} -> {answer}\")\n",
    "\n",
    "answer = clf(rot_moralFoundation + \" \" + tokenizer.sep_token + \" \" + yta_comment)\n",
    "print(f\"{yta_comment} -> {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If it's for your best, than do not worry about it. -> [{'label': 'NTA', 'score': 0.9928336143493652}]\n",
      "You shouldn't have done that, it's not allowed. -> [{'label': 'NTA', 'score': 0.6566068530082703}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"rot-categories and comments\"\"\"\n",
    "\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "model_path = '/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification_rot-categories_and_comments'\n",
    "\n",
    "rot_category = 'morality-ethics'\n",
    "nta_comment = \"If it's for your best, than do not worry about it.\"\n",
    "yta_comment = \"You shouldn't have done that, it's not allowed.\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "clf = pipeline(\"text-classification\", model=model_path, tokenizer=tokenizer)\n",
    "\n",
    "answer = clf(rot_category + \" \" + tokenizer.sep_token + \" \" + nta_comment)\n",
    "print(f\"{nta_comment} -> {answer}\")\n",
    "\n",
    "answer = clf(rot_category + \" \" + tokenizer.sep_token + \" \" + yta_comment)\n",
    "print(f\"{yta_comment} -> {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If it's for your best, than do not worry about it. -> [{'label': 'NTA', 'score': 0.9857268929481506}]\n",
      "You shouldn't have done that, it's not allowed. -> [{'label': 'YTA', 'score': 0.8293914794921875}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"AuthorId and comments\"\"\"\n",
    "\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "model_path = '/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification_authorId_and_comments'\n",
    "\n",
    "authorId = 'ei9ofvo'\n",
    "nta_comment = \"If it's for your best, than do not worry about it.\"\n",
    "yta_comment = \"You shouldn't have done that, it's not allowed.\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "clf = pipeline(\"text-classification\", model=model_path, tokenizer=tokenizer)\n",
    "\n",
    "answer = clf(authorId + \". \" + nta_comment)\n",
    "print(f\"{nta_comment} -> {answer}\")\n",
    "\n",
    "answer = clf(authorId + \". \" + yta_comment)\n",
    "print(f\"{yta_comment} -> {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If it's for your best, than do not worry about it. -> [{'label': 'NTA', 'score': 0.9942271709442139}]\n",
      "You shouldn't have done that, it's not allowed. -> [{'label': 'NTA', 'score': 0.9426610469818115}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Situations and AuthorId and comments\"\"\"\n",
    "\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "model_path = '/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification_situations_authorId_and_comments'\n",
    "\n",
    "authorId = 'ei9ofvo'\n",
    "situation = \"Want to study abroad, but feel bad leaving my country.\"\n",
    "\n",
    "nta_comment = \"If it's for your best, than do not worry about it.\"\n",
    "yta_comment = \"You shouldn't have done that, it's not allowed.\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "clf = pipeline(\"text-classification\", model=model_path, tokenizer=tokenizer)\n",
    "\n",
    "answer = clf( situation + \" \" + tokenizer.sep_token + \" \" + (authorId + \". \" + nta_comment) )\n",
    "print(f\"{nta_comment} -> {answer}\")\n",
    "\n",
    "answer = clf( situation + \" \" + tokenizer.sep_token + \" \" +  (authorId + \". \" + yta_comment) )\n",
    "print(f\"{yta_comment} -> {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference with examples from the test dataset -> CORRECT cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'ec9nvqg',\n",
       " 'permalink': '/r/AmItheAsshole/comments/a8cvvc/aita_for_asking_my_fiancÃ©_for_a_heads_up_when/ec9nvqg/',\n",
       " 'label': 'NTA',\n",
       " 'body': ' youre not saying he cant invite someone over youre asking for a simple text or phone call before you get home so you can melly prepare yourself',\n",
       " 'parent_id': 'a8cvvc',\n",
       " 'author_fullname': 't2_2n4q22oj',\n",
       " 'author_name': 'callmelola32',\n",
       " '__index_level_0__': 17521}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nta_data = social_comments_dataset['test'][2]\n",
    "nta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asking my fiancÃ© for a heads up when having people to our apartment'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "situationId_to_situation[nta_data['parent_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'ek6fhlk',\n",
       " 'permalink': '/r/AmItheAsshole/comments/b9pu2q/wibta_if_i_cut_my_childfree_kids_out_of_my_will/ek6fhlk/',\n",
       " 'label': 'YTA',\n",
       " 'body': ' you start by saying that you arent trying to coerce them into having children but then you also state later on that you are hoping they will grow out of it you are making it extremely clear that because you dont agree with their beliefs they are worth less than your children who are choosing to have kids you have no idea how this is going to tear your family apart if you cut them out of your will why is spending money on their childfree lifestyle so much more unimportant than your kids who are having children this is just a complete manipulation tactic on your part ',\n",
       " 'parent_id': 'b9pu2q',\n",
       " 'author_fullname': 't2_nlqcc',\n",
       " 'author_name': 'MissMamanda',\n",
       " '__index_level_0__': 88625}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yta_data = social_comments_dataset['test'][1]\n",
    "yta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cutting my \"child-free\" kids out of my will'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "situationId_to_situation[yta_data['parent_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTA comment -> [{'label': 'NTA', 'score': 0.9988065958023071}]\n",
      "YTA comment -> [{'label': 'YTA', 'score': 0.9932330250740051}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Only comments\"\"\"\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "model_path = '/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification'\n",
    "\n",
    "nta_comment = nta_data['body']\n",
    "yta_comment = yta_data['body']\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "clf = pipeline(\"text-classification\", model=model_path, tokenizer=tokenizer)\n",
    "\n",
    "answer = clf(nta_comment)\n",
    "print(f\"NTA comment -> {answer}\")\n",
    "\n",
    "answer = clf(yta_comment)\n",
    "print(f\"YTA comment -> {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTA input: asking my fiancÃ© for a heads up when having people to our apartment [SEP]  youre not saying he cant invite someone over youre asking for a simple text or phone call before you get home so you can melly prepare yourself\n",
      "YTA input: cutting my \"child-free\" kids out of my will [SEP]  you start by saying that you arent trying to coerce them into having children but then you also state later on that you are hoping they will grow out of it you are making it extremely clear that because you dont agree with their beliefs they are worth less than your children who are choosing to have kids you have no idea how this is going to tear your family apart if you cut them out of your will why is spending money on their childfree lifestyle so much more unimportant than your kids who are having children this is just a complete manipulation tactic on your part \n",
      "NTA comment -> [{'label': 'NTA', 'score': 0.9994131326675415}]\n",
      "YTA comment -> [{'label': 'YTA', 'score': 0.996910035610199}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Situations and comments\"\"\"\n",
    "\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "model_path = '/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification_situations_and_comments'\n",
    "\n",
    "nta_situation = situationId_to_situation[nta_data['parent_id']]\n",
    "yta_situation = situationId_to_situation[yta_data['parent_id']]\n",
    "\n",
    "nta_comment = nta_data['body']\n",
    "yta_comment = yta_data['body']\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "clf = pipeline(\"text-classification\", model=model_path, tokenizer=tokenizer)\n",
    "\n",
    "nta_input = nta_situation + \" \" + tokenizer.sep_token + \" \" + nta_comment\n",
    "yta_input = yta_situation + \" \" + tokenizer.sep_token + \" \" + yta_comment\n",
    "\n",
    "print(f\"NTA input: {nta_input}\")\n",
    "print(f\"YTA input: {yta_input}\")\n",
    "\n",
    "answer = clf(nta_input)\n",
    "print(f\"NTA comment -> {answer}\")\n",
    "\n",
    "answer = clf(yta_input)\n",
    "print(f\"YTA comment -> {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTA comment -> NTA, with score 0.9994131326675415\n",
      "YTA comment -> YTA, with score 0.996910035610199\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, pipeline, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model_path = '/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification_situations_and_comments'\n",
    "finetuned_model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "nta_situation = situationId_to_situation[nta_data['parent_id']]\n",
    "yta_situation = situationId_to_situation[yta_data['parent_id']]\n",
    "\n",
    "nta_comment = nta_data['body']\n",
    "yta_comment = yta_data['body']\n",
    "\n",
    "\n",
    "nta_input = tokenizer(nta_situation, nta_comment, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "yta_input = tokenizer(yta_situation, yta_comment, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    nta_outputs = finetuned_model(**nta_input)\n",
    "    yta_outputs = finetuned_model(**yta_input)\n",
    "\n",
    "nta_logits = nta_outputs.logits\n",
    "yta_logits = yta_outputs.logits\n",
    "\n",
    "nta_predicted_class_id = id2label[nta_logits.argmax().item()]\n",
    "yta_predicted_class_id = id2label[yta_logits.argmax().item()]\n",
    "\n",
    "nta_probability = F.softmax(nta_outputs.logits, dim=1)\n",
    "yta_probability = F.softmax(yta_outputs.logits, dim=1)\n",
    "\n",
    "print(f\"NTA comment -> {nta_predicted_class_id}, with score {nta_probability[0, label2id[nta_predicted_class_id]].item()}\")\n",
    "\n",
    "print(f\"YTA comment -> {yta_predicted_class_id}, with score {yta_probability[0, label2id[yta_predicted_class_id]].item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTA comment -> [{'label': 'NTA', 'score': 0.9993882179260254}]\n",
      "YTA comment -> [{'label': 'YTA', 'score': 0.9943819642066956}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"rot-moralFoundations and comments\"\"\"\n",
    "\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "model_path = '/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification_rot-moralFoundations_and_comments'\n",
    "\n",
    "nta_rot_moralFoundations = '. '.join(situationId_to_ROT_moral_foundations[nta_data['parent_id']])\n",
    "yta_rot_moralFoundations = '. '.join(situationId_to_ROT_moral_foundations[yta_data['parent_id']])\n",
    "\n",
    "nta_comment = nta_data['body']\n",
    "yta_comment = yta_data['body']\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "clf = pipeline(\"text-classification\", model=model_path, tokenizer=tokenizer)\n",
    "\n",
    "answer = clf(nta_rot_moralFoundations + \" \" + tokenizer.sep_token + \" \" + nta_comment)\n",
    "print(f\"NTA comment -> {answer}\")\n",
    "\n",
    "answer = clf(yta_rot_moralFoundations + \" \" + tokenizer.sep_token + \" \" + yta_comment)\n",
    "print(f\"YTA comment -> {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTA comment -> NTA, with score 0.9993882179260254\n",
      "YTA comment -> YTA, with score 0.9943819642066956\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, pipeline, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model_path = '/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification_rot-moralFoundations_and_comments'\n",
    "finetuned_model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "nta_rot_moralFoundations = '. '.join(situationId_to_ROT_moral_foundations[nta_data['parent_id']])\n",
    "yta_rot_moralFoundations = '. '.join(situationId_to_ROT_moral_foundations[yta_data['parent_id']])\n",
    "\n",
    "nta_comment = nta_data['body']\n",
    "yta_comment = yta_data['body']\n",
    "\n",
    "nta_input = tokenizer(nta_rot_moralFoundations, nta_comment, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "yta_input = tokenizer(yta_rot_moralFoundations, yta_comment, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    nta_outputs = finetuned_model(**nta_input)\n",
    "   \n",
    "with torch.no_grad():\n",
    "    yta_outputs = finetuned_model(**yta_input)\n",
    "\n",
    "nta_logits = nta_outputs.logits\n",
    "yta_logits = yta_outputs.logits\n",
    "\n",
    "nta_predicted_class_id = id2label[nta_logits.argmax().item()]\n",
    "yta_predicted_class_id = id2label[yta_logits.argmax().item()]\n",
    "\n",
    "nta_probability = F.softmax(nta_outputs.logits, dim=1)\n",
    "yta_probability = F.softmax(yta_outputs.logits, dim=1)\n",
    "\n",
    "print(f\"NTA comment -> {nta_predicted_class_id}, with score {nta_probability[0, label2id[nta_predicted_class_id]].item()}\")\n",
    "\n",
    "print(f\"YTA comment -> {yta_predicted_class_id}, with score {yta_probability[0, label2id[yta_predicted_class_id]].item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTA comment -> [{'label': 'NTA', 'score': 0.9990286827087402}]\n",
      "YTA comment -> [{'label': 'YTA', 'score': 0.9954793453216553}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"rot-categories and comments\"\"\"\n",
    "\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "model_path = '/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification_rot-categories_and_comments'\n",
    "\n",
    "nta_rot_categories = '. '.join(situationId_to_ROT_categories[nta_data['parent_id']])\n",
    "yta_rot_categories = '. '.join(situationId_to_ROT_categories[yta_data['parent_id']])\n",
    "\n",
    "nta_comment = nta_data['body']\n",
    "yta_comment = yta_data['body']\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "clf = pipeline(\"text-classification\", model=model_path, tokenizer=tokenizer)\n",
    "\n",
    "answer = clf(nta_rot_categories + \" \" + tokenizer.sep_token + \" \" + nta_comment)\n",
    "print(f\"NTA comment -> {answer}\")\n",
    "\n",
    "answer = clf(yta_rot_categories + \" \" + tokenizer.sep_token + \" \" + yta_comment)\n",
    "print(f\"YTA comment -> {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTA comment -> NTA, with score 0.9990286827087402\n",
      "YTA comment -> YTA, with score 0.9954793453216553\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, pipeline, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model_path = '/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification_rot-categories_and_comments'\n",
    "finetuned_model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "nta_rot_categories = '. '.join(situationId_to_ROT_categories[nta_data['parent_id']])\n",
    "yta_rot_categories = '. '.join(situationId_to_ROT_categories[yta_data['parent_id']])\n",
    "\n",
    "nta_comment = nta_data['body']\n",
    "yta_comment = yta_data['body']\n",
    "\n",
    "nta_input = tokenizer(nta_rot_categories, nta_comment, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "yta_input = tokenizer(yta_rot_categories, yta_comment, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    nta_outputs = finetuned_model(**nta_input)\n",
    "   \n",
    "with torch.no_grad():\n",
    "    yta_outputs = finetuned_model(**yta_input)\n",
    "\n",
    "nta_logits = nta_outputs.logits\n",
    "yta_logits = yta_outputs.logits\n",
    "\n",
    "nta_predicted_class_id = id2label[nta_logits.argmax().item()]\n",
    "yta_predicted_class_id = id2label[yta_logits.argmax().item()]\n",
    "\n",
    "nta_probability = F.softmax(nta_outputs.logits, dim=1)\n",
    "yta_probability = F.softmax(yta_outputs.logits, dim=1)\n",
    "\n",
    "print(f\"NTA comment -> {nta_predicted_class_id}, with score {nta_probability[0, label2id[nta_predicted_class_id]].item()}\")\n",
    "\n",
    "print(f\"YTA comment -> {yta_predicted_class_id}, with score {yta_probability[0, label2id[yta_predicted_class_id]].item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTA comment -> [{'label': 'NTA', 'score': 0.9992976188659668}]\n",
      "YTA comment -> [{'label': 'YTA', 'score': 0.9959738850593567}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"AuthorId and comments\"\"\"\n",
    "\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "model_path = '/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification_authorId_and_comments'\n",
    "\n",
    "nta_authorId = nta_data['id']\n",
    "yta_authorId = yta_data['id']\n",
    "\n",
    "nta_comment = nta_data['body']\n",
    "yta_comment = yta_data['body']\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "clf = pipeline(\"text-classification\", model=model_path, tokenizer=tokenizer)\n",
    "\n",
    "answer = clf(nta_authorId + \". \" + nta_comment)\n",
    "print(f\"NTA comment -> {answer}\")\n",
    "\n",
    "answer = clf(yta_authorId + \". \" + yta_comment)\n",
    "print(f\"YTA comment -> {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTA comment -> NTA, with score 0.9992976188659668\n",
      "YTA comment -> YTA, with score 0.9959738850593567\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, pipeline, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model_path = '/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification_authorId_and_comments'\n",
    "finetuned_model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "nta_authorId = nta_data['id']\n",
    "yta_authorId = yta_data['id']\n",
    "\n",
    "nta_comment = nta_data['body']\n",
    "yta_comment = yta_data['body']\n",
    "\n",
    "nta_text = nta_authorId + \". \" + nta_comment\n",
    "yta_text = yta_authorId + \". \" + yta_comment\n",
    "\n",
    "nta_input = tokenizer(nta_text, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "yta_input = tokenizer(yta_text, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    nta_outputs = finetuned_model(**nta_input)\n",
    "   \n",
    "with torch.no_grad():\n",
    "    yta_outputs = finetuned_model(**yta_input)\n",
    "\n",
    "nta_logits = nta_outputs.logits\n",
    "yta_logits = yta_outputs.logits\n",
    "\n",
    "nta_predicted_class_id = id2label[nta_logits.argmax().item()]\n",
    "yta_predicted_class_id = id2label[yta_logits.argmax().item()]\n",
    "\n",
    "nta_probability = F.softmax(nta_outputs.logits, dim=1)\n",
    "yta_probability = F.softmax(yta_outputs.logits, dim=1)\n",
    "\n",
    "print(f\"NTA comment -> {nta_predicted_class_id}, with score {nta_probability[0, label2id[nta_predicted_class_id]].item()}\")\n",
    "\n",
    "print(f\"YTA comment -> {yta_predicted_class_id}, with score {yta_probability[0, label2id[yta_predicted_class_id]].item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTA comment -> [{'label': 'NTA', 'score': 0.9993768334388733}]\n",
      "YTA comment -> [{'label': 'YTA', 'score': 0.9959113597869873}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Situations and AuthorId and comments\"\"\"\n",
    "\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "model_path = '/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification_situations_authorId_and_comments'\n",
    "\n",
    "nta_authorId = nta_data['id']\n",
    "yta_authorId = yta_data['id']\n",
    "\n",
    "nta_comment = nta_data['body']\n",
    "yta_comment = yta_data['body']\n",
    "\n",
    "nta_text = nta_authorId + \". \" + nta_comment\n",
    "yta_text = yta_authorId + \". \" + yta_comment\n",
    "\n",
    "nta_situation = situationId_to_situation[nta_data['parent_id']]\n",
    "yta_situation = situationId_to_situation[yta_data['parent_id']]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "clf = pipeline(\"text-classification\", model=model_path, tokenizer=tokenizer)\n",
    "\n",
    "answer = clf( nta_text + \" \" + tokenizer.sep_token + \" \" + nta_situation )\n",
    "print(f\"NTA comment -> {answer}\")\n",
    "\n",
    "answer = clf( yta_text + \" \" + tokenizer.sep_token + \" \" +  yta_situation )\n",
    "print(f\"YTA comment -> {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTA comment -> NTA, with score 0.9993768334388733\n",
      "YTA comment -> YTA, with score 0.9959113597869873\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, pipeline, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model_path = '/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification_situations_authorId_and_comments'\n",
    "finetuned_model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "nta_authorId = nta_data['id']\n",
    "yta_authorId = yta_data['id']\n",
    "\n",
    "nta_comment = nta_data['body']\n",
    "yta_comment = yta_data['body']\n",
    "\n",
    "nta_text = nta_authorId + \". \" + nta_comment\n",
    "yta_text = yta_authorId + \". \" + yta_comment\n",
    "\n",
    "nta_situation = situationId_to_situation[nta_data['parent_id']]\n",
    "yta_situation = situationId_to_situation[yta_data['parent_id']]\n",
    "\n",
    "nta_input = tokenizer(nta_text, nta_situation, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "yta_input = tokenizer(yta_text, yta_situation, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    nta_outputs = finetuned_model(**nta_input)\n",
    "   \n",
    "with torch.no_grad():\n",
    "    yta_outputs = finetuned_model(**yta_input)\n",
    "\n",
    "nta_logits = nta_outputs.logits\n",
    "yta_logits = yta_outputs.logits\n",
    "\n",
    "nta_predicted_class_id = id2label[nta_logits.argmax().item()]\n",
    "yta_predicted_class_id = id2label[yta_logits.argmax().item()]\n",
    "\n",
    "nta_probability = F.softmax(nta_outputs.logits, dim=1)\n",
    "yta_probability = F.softmax(yta_outputs.logits, dim=1)\n",
    "\n",
    "print(f\"NTA comment -> {nta_predicted_class_id}, with score {nta_probability[0, label2id[nta_predicted_class_id]].item()}\")\n",
    "\n",
    "print(f\"YTA comment -> {yta_predicted_class_id}, with score {yta_probability[0, label2id[yta_predicted_class_id]].item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference with examples from the test dataset -> FAILURE cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'eivr3oy',\n",
       " 'permalink': '/r/AmItheAsshole/comments/b2yamg/aita_for_breaking_off_my_engagement_over_his/eivr3oy/',\n",
       " 'label': 'NTA',\n",
       " 'body': ' he cant help how his parents are but you gave him an out by confronting him and asking if he was a racist his nonresponse is all you really needed you went into the wedding with the intention of marrying him and then you realized that it wasnt a decision that you would be happy with for the rest of your life due to new information nobody can ask more of you than that ',\n",
       " 'parent_id': 'b2yamg',\n",
       " 'author_fullname': 't2_6u2o6',\n",
       " 'author_name': 'Jayrodtremonki',\n",
       " '__index_level_0__': 359384}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nta_data = social_comments_dataset['test'][0]\n",
    "nta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"breaking off my engagement over his father's racist remarks\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "situationId_to_situation[nta_data['parent_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'edtxoas',\n",
       " 'permalink': '/r/AmItheAsshole/comments/aex00x/aita_for_being_annoyed_because_my_girlfriend_pees/edtxoas/',\n",
       " 'label': 'YTA',\n",
       " 'body': 'honestly i would be more concerned on why she has to go so frequently i would think there is something wrong and yeah it kinda sounds like ',\n",
       " 'parent_id': 'aex00x',\n",
       " 'author_fullname': 't2_2vgdjz0c',\n",
       " 'author_name': 'Dotori_Dan',\n",
       " '__index_level_0__': 250034}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yta_data = social_comments_dataset['test'][10]\n",
    "yta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'being annoyed because my girlfriend pees so much'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "situationId_to_situation[yta_data['parent_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTA comment -> [{'label': 'YTA', 'score': 0.9471924304962158}]\n",
      "YTA comment -> [{'label': 'NTA', 'score': 0.9383085370063782}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Only comments\"\"\"\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "model_path = '/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification'\n",
    "\n",
    "nta_comment = nta_data['body']\n",
    "yta_comment = yta_data['body']\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "clf = pipeline(\"text-classification\", model=model_path, tokenizer=tokenizer)\n",
    "\n",
    "answer = clf(nta_comment)\n",
    "print(f\"NTA comment -> {answer}\") #confused as YTA, maybe because how the comment starts: \"he cant help how his parents are\", which indicates initially that the asker is wrong, but then the comment changes notation and the commenter gives the right to the asker\n",
    "\n",
    "answer = clf(yta_comment)\n",
    "print(f\"YTA comment -> {answer}\") #confused as NTA, maybe because it is an ironic comment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'honestly i would be more concerned on why she has to go so frequently i would think there is something wrong and yeah it kinda sounds like '"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yta_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTA input: breaking off my engagement over his father's racist remarks [SEP]  he cant help how his parents are but you gave him an out by confronting him and asking if he was a racist his nonresponse is all you really needed you went into the wedding with the intention of marrying him and then you realized that it wasnt a decision that you would be happy with for the rest of your life due to new information nobody can ask more of you than that \n",
      "YTA input: being annoyed because my girlfriend pees so much [SEP] honestly i would be more concerned on why she has to go so frequently i would think there is something wrong and yeah it kinda sounds like \n",
      "NTA comment -> [{'label': 'YTA', 'score': 0.978890597820282}]\n",
      "YTA comment -> [{'label': 'YTA', 'score': 0.827903151512146}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Situations and comments\"\"\"\n",
    "\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "model_path = '/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification_situations_and_comments'\n",
    "\n",
    "nta_situation = situationId_to_situation[nta_data['parent_id']]\n",
    "yta_situation = situationId_to_situation[yta_data['parent_id']]\n",
    "\n",
    "nta_comment = nta_data['body']\n",
    "yta_comment = yta_data['body']\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "clf = pipeline(\"text-classification\", model=model_path, tokenizer=tokenizer)\n",
    "\n",
    "nta_input = nta_situation + \" \" + tokenizer.sep_token + \" \" + nta_comment\n",
    "yta_input = yta_situation + \" \" + tokenizer.sep_token + \" \" + yta_comment\n",
    "\n",
    "print(f\"NTA input: {nta_input}\")\n",
    "print(f\"YTA input: {yta_input}\")\n",
    "\n",
    "answer = clf(nta_input)\n",
    "print(f\"NTA comment -> {answer}\") #confused as YTA maybe because how the comment starts: \"he cant help how his parents are\", which indicates initially that the asker is wrong, but then the comment changes notation and the commenter gives the right to the asker\n",
    "\n",
    "answer = clf(yta_input)\n",
    "print(f\"YTA comment -> {answer}\") #The only model that predicts it correctly!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTA comment -> YTA, with score 0.978890597820282\n",
      "YTA comment -> YTA, with score 0.8279033899307251\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, pipeline, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model_path = '/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification_situations_and_comments'\n",
    "finetuned_model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "nta_situation = situationId_to_situation[nta_data['parent_id']]\n",
    "yta_situation = situationId_to_situation[yta_data['parent_id']]\n",
    "\n",
    "nta_comment = nta_data['body']\n",
    "yta_comment = yta_data['body']\n",
    "\n",
    "\n",
    "nta_input = tokenizer(nta_situation, nta_comment, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "yta_input = tokenizer(yta_situation, yta_comment, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    nta_outputs = finetuned_model(**nta_input)\n",
    "    yta_outputs = finetuned_model(**yta_input)\n",
    "\n",
    "nta_logits = nta_outputs.logits\n",
    "yta_logits = yta_outputs.logits\n",
    "\n",
    "nta_predicted_class_id = id2label[nta_logits.argmax().item()]\n",
    "yta_predicted_class_id = id2label[yta_logits.argmax().item()]\n",
    "\n",
    "nta_probability = F.softmax(nta_outputs.logits, dim=1)\n",
    "yta_probability = F.softmax(yta_outputs.logits, dim=1)\n",
    "\n",
    "print(f\"NTA comment -> {nta_predicted_class_id}, with score {nta_probability[0, label2id[nta_predicted_class_id]].item()}\")\n",
    "\n",
    "print(f\"YTA comment -> {yta_predicted_class_id}, with score {yta_probability[0, label2id[yta_predicted_class_id]].item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTA comment -> [{'label': 'YTA', 'score': 0.9737996459007263}]\n",
      "YTA comment -> [{'label': 'NTA', 'score': 0.9811087250709534}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"rot-moralFoundations and comments\"\"\"\n",
    "\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "model_path = '/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification_rot-moralFoundations_and_comments'\n",
    "\n",
    "nta_rot_moralFoundations = '. '.join(situationId_to_ROT_moral_foundations[nta_data['parent_id']])\n",
    "yta_rot_moralFoundations = '. '.join(situationId_to_ROT_moral_foundations[yta_data['parent_id']])\n",
    "\n",
    "nta_comment = nta_data['body']\n",
    "yta_comment = yta_data['body']\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "clf = pipeline(\"text-classification\", model=model_path, tokenizer=tokenizer)\n",
    "\n",
    "answer = clf(nta_rot_moralFoundations + \" \" + tokenizer.sep_token + \" \" + nta_comment)\n",
    "print(f\"NTA comment -> {answer}\")\n",
    "\n",
    "answer = clf(yta_rot_moralFoundations + \" \" + tokenizer.sep_token + \" \" + yta_comment)\n",
    "print(f\"YTA comment -> {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTA comment -> YTA, with score 0.9737995266914368\n",
      "YTA comment -> NTA, with score 0.9811088442802429\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, pipeline, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model_path = '/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification_rot-moralFoundations_and_comments'\n",
    "finetuned_model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "nta_rot_moralFoundations = '. '.join(situationId_to_ROT_moral_foundations[nta_data['parent_id']])\n",
    "yta_rot_moralFoundations = '. '.join(situationId_to_ROT_moral_foundations[yta_data['parent_id']])\n",
    "\n",
    "nta_comment = nta_data['body']\n",
    "yta_comment = yta_data['body']\n",
    "\n",
    "nta_input = tokenizer(nta_rot_moralFoundations, nta_comment, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "yta_input = tokenizer(yta_rot_moralFoundations, yta_comment, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    nta_outputs = finetuned_model(**nta_input)\n",
    "   \n",
    "with torch.no_grad():\n",
    "    yta_outputs = finetuned_model(**yta_input)\n",
    "\n",
    "nta_logits = nta_outputs.logits\n",
    "yta_logits = yta_outputs.logits\n",
    "\n",
    "nta_predicted_class_id = id2label[nta_logits.argmax().item()]\n",
    "yta_predicted_class_id = id2label[yta_logits.argmax().item()]\n",
    "\n",
    "nta_probability = F.softmax(nta_outputs.logits, dim=1)\n",
    "yta_probability = F.softmax(yta_outputs.logits, dim=1)\n",
    "\n",
    "print(f\"NTA comment -> {nta_predicted_class_id}, with score {nta_probability[0, label2id[nta_predicted_class_id]].item()}\")\n",
    "\n",
    "print(f\"YTA comment -> {yta_predicted_class_id}, with score {yta_probability[0, label2id[yta_predicted_class_id]].item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTA comment -> [{'label': 'YTA', 'score': 0.9883868098258972}]\n",
      "YTA comment -> [{'label': 'NTA', 'score': 0.9296041131019592}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"rot-categories and comments\"\"\"\n",
    "\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "model_path = '/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification_rot-categories_and_comments'\n",
    "\n",
    "nta_rot_categories = '. '.join(situationId_to_ROT_categories[nta_data['parent_id']])\n",
    "yta_rot_categories = '. '.join(situationId_to_ROT_categories[yta_data['parent_id']])\n",
    "\n",
    "nta_comment = nta_data['body']\n",
    "yta_comment = yta_data['body']\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "clf = pipeline(\"text-classification\", model=model_path, tokenizer=tokenizer)\n",
    "\n",
    "answer = clf(nta_rot_categories + \" \" + tokenizer.sep_token + \" \" + nta_comment)\n",
    "print(f\"NTA comment -> {answer}\")\n",
    "\n",
    "answer = clf(yta_rot_categories + \" \" + tokenizer.sep_token + \" \" + yta_comment)\n",
    "print(f\"YTA comment -> {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTA comment -> [{'label': 'YTA', 'score': 0.9721246957778931}]\n",
      "YTA comment -> [{'label': 'NTA', 'score': 0.9558769464492798}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"AuthorId and comments\"\"\"\n",
    "\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "model_path = '/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification_authorId_and_comments'\n",
    "\n",
    "nta_authorId = nta_data['id']\n",
    "yta_authorId = yta_data['id']\n",
    "\n",
    "nta_comment = nta_data['body']\n",
    "yta_comment = yta_data['body']\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "clf = pipeline(\"text-classification\", model=model_path, tokenizer=tokenizer)\n",
    "\n",
    "answer = clf(nta_authorId + \". \" + nta_comment)\n",
    "print(f\"NTA comment -> {answer}\")\n",
    "\n",
    "answer = clf(yta_authorId + \". \" + yta_comment)\n",
    "print(f\"YTA comment -> {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTA comment -> YTA, with score 0.9721246957778931\n",
      "YTA comment -> NTA, with score 0.9558769464492798\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, pipeline, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model_path = '/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification_authorId_and_comments'\n",
    "finetuned_model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "nta_authorId = nta_data['id']\n",
    "yta_authorId = yta_data['id']\n",
    "\n",
    "nta_comment = nta_data['body']\n",
    "yta_comment = yta_data['body']\n",
    "\n",
    "nta_text = nta_authorId + \". \" + nta_comment\n",
    "yta_text = yta_authorId + \". \" + yta_comment\n",
    "\n",
    "nta_input = tokenizer(nta_text, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "yta_input = tokenizer(yta_text, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    nta_outputs = finetuned_model(**nta_input)\n",
    "   \n",
    "with torch.no_grad():\n",
    "    yta_outputs = finetuned_model(**yta_input)\n",
    "\n",
    "nta_logits = nta_outputs.logits\n",
    "yta_logits = yta_outputs.logits\n",
    "\n",
    "nta_predicted_class_id = id2label[nta_logits.argmax().item()]\n",
    "yta_predicted_class_id = id2label[yta_logits.argmax().item()]\n",
    "\n",
    "nta_probability = F.softmax(nta_outputs.logits, dim=1)\n",
    "yta_probability = F.softmax(yta_outputs.logits, dim=1)\n",
    "\n",
    "print(f\"NTA comment -> {nta_predicted_class_id}, with score {nta_probability[0, label2id[nta_predicted_class_id]].item()}\")\n",
    "\n",
    "print(f\"YTA comment -> {yta_predicted_class_id}, with score {yta_probability[0, label2id[yta_predicted_class_id]].item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTA comment -> [{'label': 'YTA', 'score': 0.9664369821548462}]\n",
      "YTA comment -> [{'label': 'YTA', 'score': 0.9623212218284607}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Situations and AuthorId and comments\"\"\"\n",
    "\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "model_path = '/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification_situations_authorId_and_comments'\n",
    "\n",
    "nta_authorId = nta_data['id']\n",
    "yta_authorId = yta_data['id']\n",
    "\n",
    "nta_comment = nta_data['body']\n",
    "yta_comment = yta_data['body']\n",
    "\n",
    "nta_text = nta_authorId + \". \" + nta_comment\n",
    "yta_text = yta_authorId + \". \" + yta_comment\n",
    "\n",
    "nta_situation = situationId_to_situation[nta_data['parent_id']]\n",
    "yta_situation = situationId_to_situation[yta_data['parent_id']]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "clf = pipeline(\"text-classification\", model=model_path, tokenizer=tokenizer)\n",
    "\n",
    "answer = clf( nta_text + \" \" + tokenizer.sep_token + \" \" + nta_situation )\n",
    "print(f\"NTA comment -> {answer}\")\n",
    "\n",
    "answer = clf( yta_text + \" \" + tokenizer.sep_token + \" \" +  yta_situation ) #predicts this correctly same as in situatuon + comment \n",
    "print(f\"YTA comment -> {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTA comment -> YTA, with score 0.9664369821548462\n",
      "YTA comment -> YTA, with score 0.9623212218284607\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, pipeline, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model_path = '/home/IAIS/gplepi/entero/output_social_norms/bert_comments_classification_situations_authorId_and_comments'\n",
    "finetuned_model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "nta_authorId = nta_data['id']\n",
    "yta_authorId = yta_data['id']\n",
    "\n",
    "nta_comment = nta_data['body']\n",
    "yta_comment = yta_data['body']\n",
    "\n",
    "nta_text = nta_authorId + \". \" + nta_comment\n",
    "yta_text = yta_authorId + \". \" + yta_comment\n",
    "\n",
    "nta_situation = situationId_to_situation[nta_data['parent_id']]\n",
    "yta_situation = situationId_to_situation[yta_data['parent_id']]\n",
    "\n",
    "nta_input = tokenizer(nta_text, nta_situation, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "yta_input = tokenizer(yta_text, yta_situation, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    nta_outputs = finetuned_model(**nta_input)\n",
    "   \n",
    "with torch.no_grad():\n",
    "    yta_outputs = finetuned_model(**yta_input)\n",
    "\n",
    "nta_logits = nta_outputs.logits\n",
    "yta_logits = yta_outputs.logits\n",
    "\n",
    "nta_predicted_class_id = id2label[nta_logits.argmax().item()]\n",
    "yta_predicted_class_id = id2label[yta_logits.argmax().item()]\n",
    "\n",
    "nta_probability = F.softmax(nta_outputs.logits, dim=1)\n",
    "yta_probability = F.softmax(yta_outputs.logits, dim=1)\n",
    "\n",
    "print(f\"NTA comment -> {nta_predicted_class_id}, with score {nta_probability[0, label2id[nta_predicted_class_id]].item()}\")\n",
    "\n",
    "print(f\"YTA comment -> {yta_predicted_class_id}, with score {yta_probability[0, label2id[yta_predicted_class_id]].item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entero_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
